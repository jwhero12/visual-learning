{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "import random"
      ],
      "metadata": {
        "id": "DGvoLLY6Xu7h"
      },
      "id": "DGvoLLY6Xu7h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"images/Image_09L.jpg\"\n",
        "base_dataset_dir = \"dataset/\"\n",
        "base_results_dir = \"results/\"\n",
        "grid_size = 5\n",
        "sam2_checkpoint = \"../checkpoints/sam2.1_hiera_tiny.pt\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
        "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "TIDBmZMEXwee"
      },
      "id": "TIDBmZMEXwee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime(\"%m%d%H%M\")\n",
        "dataset_dir = os.path.join(base_dataset_dir, timestamp)\n",
        "results_dir = os.path.join(base_results_dir, timestamp)\n",
        "unmasked_dir = os.path.join(results_dir, \"unmasked\")\n",
        "masked_dir = os.path.join(results_dir, \"masked\")\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "os.makedirs(unmasked_dir, exist_ok=True)\n",
        "os.makedirs(masked_dir, exist_ok=True)\n",
        "\n",
        "print(\"Starting preprocessing...\")\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "if image is None:\n",
        "    raise FileNotFoundError(f\"Image not found at path: {image_path}. Please check the file path.\")"
      ],
      "metadata": {
        "id": "hs67PCUHXz1F"
      },
      "id": "hs67PCUHXz1F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "green_channel = image[:, :, 1]\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "enhanced_img = clahe.apply(green_channel)\n",
        "\n",
        "blurred_img = cv2.GaussianBlur(enhanced_img, (5, 5), sigmaX=1.0)\n",
        "\n",
        "kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
        "sharpened_img = cv2.filter2D(blurred_img, -1, kernel)\n",
        "\n",
        "preprocessed_image_path = os.path.join(results_dir, \"preprocessed_image.png\")\n",
        "cv2.imwrite(preprocessed_image_path, sharpened_img)\n",
        "print(f\"Preprocessed image saved to {preprocessed_image_path}\")\n",
        "\n",
        "print(\"Splitting image into grids...\")\n",
        "h, w = sharpened_img.shape\n",
        "grid_h, grid_w = h // grid_size, w // grid_size\n",
        "\n",
        "if grid_h == 0 or grid_w == 0:\n",
        "    raise ValueError(\"Grid size is too large for the image dimensions. Reduce the grid size.\")\n",
        "\n",
        "for i in range(grid_size):\n",
        "    for j in range(grid_size):\n",
        "        y1, y2 = i * grid_h, (i + 1) * grid_h\n",
        "        x1, x2 = j * grid_w, (j + 1) * grid_w\n",
        "        sub_image = sharpened_img[y1:y2, x1:x2]\n",
        "\n",
        "        if sub_image.size == 0 or sub_image.shape[0] == 0 or sub_image.shape[1] == 0:\n",
        "            print(f\"Skipped saving grid_{i * grid_size + j} due to invalid dimensions.\")\n",
        "            continue\n",
        "\n",
        "        grid_path = os.path.join(dataset_dir, f\"grid_{i * grid_size + j}.png\")\n",
        "        cv2.imwrite(grid_path, sub_image)\n",
        "\n",
        "print(f\"Grid images saved in {dataset_dir}\")"
      ],
      "metadata": {
        "id": "LYQxRQtNX5fi"
      },
      "id": "LYQxRQtNX5fi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing SAM2 model...\")\n",
        "sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)\n",
        "mask_generator = SAM2AutomaticMaskGenerator(\n",
        "    model=sam2,\n",
        "    points_per_side=128,\n",
        "    points_per_batch=16,\n",
        "    pred_iou_thresh=0.7,\n",
        "    stability_score_thresh=0.50,\n",
        "    stability_score_offset=0.7,\n",
        "    crop_n_layers=4,\n",
        "    box_nms_thresh=0.7,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=30.0,\n",
        "    use_m2m=True,\n",
        ")\n",
        "\n",
        "final_unmasked_area = np.ones((h, w), dtype=np.uint8)\n",
        "final_segmentation_colored = np.zeros((h, w, 3), dtype=np.uint8)"
      ],
      "metadata": {
        "id": "w6-nXgAuX9-9"
      },
      "id": "w6-nXgAuX9-9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d68d0b92-310c-425f-916d-f11adc6180db",
      "metadata": {
        "id": "d68d0b92-310c-425f-916d-f11adc6180db"
      },
      "outputs": [],
      "source": [
        "def random_color():\n",
        "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "\n",
        "print(\"Processing grids with SAM2...\")\n",
        "for grid_file in sorted(os.listdir(dataset_dir)):\n",
        "    grid_path = os.path.join(dataset_dir, grid_file)\n",
        "    sub_image = np.array(Image.open(grid_path))\n",
        "\n",
        "    grid_y = int(grid_file.split(\"_\")[1].split(\".\")[0]) // grid_size\n",
        "    grid_x = int(grid_file.split(\"_\")[1].split(\".\")[0]) % grid_size\n",
        "    y1, y2 = grid_y * grid_h, (grid_y + 1) * grid_h\n",
        "    x1, x2 = grid_x * grid_w, (grid_x + 1) * grid_w\n",
        "\n",
        "    sub_image = sub_image.astype(np.uint8)\n",
        "    try:\n",
        "        masks = mask_generator.generate(sub_image)\n",
        "        torch.cuda.empty_cache()  # 주기적 메모리 정리\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error processing {grid_file}: {e}\")\n",
        "        continue\n",
        "\n",
        "    combined_mask = np.zeros((sub_image.shape[0], sub_image.shape[1]), dtype=np.uint8)\n",
        "    unmasked_area = np.ones_like(combined_mask, dtype=np.uint8)\n",
        "\n",
        "    for mask in masks:\n",
        "        single_mask = mask['segmentation'].astype(np.uint8)\n",
        "        combined_mask = np.maximum(combined_mask, single_mask)\n",
        "        unmasked_area = np.minimum(unmasked_area, 1 - single_mask)\n",
        "\n",
        "        color = random_color()\n",
        "        final_segmentation_colored[y1:y2, x1:x2][single_mask > 0] = color\n",
        "\n",
        "    final_unmasked_area[y1:y2, x1:x2] = unmasked_area\n",
        "\n",
        "final_segmentation_path = os.path.join(results_dir, \"final_segmentation_colored.png\")\n",
        "Image.fromarray(final_segmentation_colored).save(final_segmentation_path)\n",
        "\n",
        "final_unmasked_colored = np.zeros((*final_unmasked_area.shape, 3), dtype=np.uint8)\n",
        "final_unmasked_colored[final_unmasked_area > 0] = [0, 255, 0]\n",
        "final_unmasked_path = os.path.join(results_dir, \"final_unmasked_colored.png\")\n",
        "Image.fromarray(final_unmasked_colored).save(final_unmasked_path)\n",
        "\n",
        "del sam2\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Final segmentation result saved to {final_segmentation_path}\")\n",
        "print(f\"Final unmasked result saved to {final_unmasked_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}